"""Essential Python for DA.ipynb

Automatically generated by Colab.

# **Essential Python for DA**

- Object Oriented Programming
- Read and Write file
- Context Manager
- Handle Error
- Pandas & Numpy (on demand)
- Request API
"""

"""# **OOP**"""

class Dog:
    def __init__(self, name, species, age):
        self.name = name
        self.species = species
        self.age = age

    def bark(self):
        print(f"{self.name} is barking 'hong hong'!")

    def hbd(self):
        self.age += 1

## attributes
dog1 = Dog("milo", "Chihuahua", 2)
dog2 = Dog("david", "Husky", 3)

print(f"{dog1.name} is {dog1.species}")

print(f"{dog2.name} is {dog2.species}")

dog1.bark()

dog2.bark()

print(dog1.age)
dog1.hbd()
print(dog1.age)

"""## **OOP**

* attributes: name, species, age
* methods: function bark() hbd()
"""

## homeworkd OOP for an ATM

## deposit, withdraw, check balance, OTP, order coffee, pay bill, internet etc.

class ATM:
    def __init__(self, username, bank, amount):
        self.username = username
        self.bank = bank
        self.amount = amount

    def __str__(self):
        return f"{self.username} uses {self.bank} and has {self.amount} THB in an account."

    def check_balance(self):
        print(f"Balance: {self.amount} THB")

    def deposit(self, saving):
        self.amount += saving
        print(f"Deposit {saving} THB successfully!")

toy = ATM("kasidis toy", "scb", 100)

toy.check_balance()

toy.deposit(200)

toy.check_balance()

print(toy)

## super class

class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

## extension
class Employee(Person):
    def __init__(self, name, age, company):
        super().__init__(name, age)
        self.company = company

    def greeting(self):
        print("Hello World!")

person1 = Person("toy", 37)

person2 = Employee("lisa", 28, "google")

person2.greeting()



"""# **Try Except Block**"""

try:
    result = 1/0
except:
    print("this is an error message!")

!ls

!cat hotel.csv

## read file
import csv

try:
    file = open("hotel.csv", "r") ## r w a
    data = csv.reader(file)
    for row in data:
        print(row)
    file.close()
except FileNotFoundError:
    print("file not found, please check filename again.")
finally:
    print("read file successfully.")

# context manager
read_data = []

with open("hotel.csv", "r") as file:
    data = csv.reader(file)
    for row in data:
        read_data.append(row)

# header
read_data[0]

# body data
read_data[1: ]

## for loop to calculate avg. price per night
prices = []

for row in read_data[1: ]:
    prices.append(int(row[4])) ## -1 the last item

print(f"Average price per night: {sum(prices)/ len(prices)}")

## modern python
import pandas as pd

df = pd.read_csv("hotel.csv")

df.head()

df.price_per_night.mean()

df["price_per_night"].mean()



"""## **Read & Write Files**"""

import csv

# write file + context manager
head = ["id", "name", "city"]
body = [
    [1, "CU", "Bangkok"],
    [2, "LSE", "London"],
    [3, "Reading", "Reading"]
]

with open("school.csv", "w") as file:
    writer = csv.writer(file)
    writer.writerow(head)
    writer.writerows(body)

!ls

!cat school.csv

# modern python
import pandas as pd

df = pd.read_csv("school.csv")

df.head()

# export csv file in pandas
df.to_csv("school2.csv")

!ls

!cat school2.csv

## read data from internet

url = "https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/penguins.csv"

# import pandas as pd
import pandas as pd
df_penguin = pd.read_csv(url)

df_penguin.head()

df_penguin.tail()

## select column
df_penguin[["species", "island", "body_mass_g"]].head(10)

## filter rows
df_penguin[["species", "island", "body_mass_g"]] \
    .query("species == 'Adelie' and island == 'Dream'") \
    .head(10)

## R vs. Python
# df %>%
#     select() %>%
#     filter() %>%
#     arrange()

# df.select()\
#     .filter()\
#     .arrange()

## filter without query()
df_penguin[df_penguin['body_mass_g'] >= 4500][["species", "sex", "body_mass_g"]]

## requests api



"""# Requests

How to get data via API the easy way
"""

import requests

## api endpoint
url = "https://swapi.info/api/people/1"

response = requests.get(url)

response.json()["name"]

response.json()["height"]

response.json()["mass"]

## for loop
import requests
import time

characters = []

for i in range(5):
    url = f"https://swapi.info/api/people/{i+1}"
    response = requests.get(url)
    response_json = response.json()
    data = [response_json["name"],
            response_json["height"],
            response_json["mass"]]
    characters.append(data)
    print(f"Success: {i+1}")
    time.sleep(1)

print(characters)

import pandas as pd

starwars = pd.DataFrame(characters,  columns = ["name", "height", "mass"])

starwars


## this is my first script
print("hello world")
print("I am using github with posit.cloud")

def hello():
    name = input("What's your name: ")
    print(f"Hello {name}!")

# test function
hello()

## syntax
lambda ตามด้วย argument : expression ที่จะทำกับ input พวกนั้น

## lambda
test = lambda x : print(x)

add_two = lambda num: print(num+2)

## map / filter
## iterable (adj)
scores = [82, 78, 81, 66, 50]
def grading(score):
  if score >= 80:
    return "passed"
  else:
    return "failed"
list(map(grading, scores))

## add five to scores
list(map(lambda x: x+5, scores))

list(filter(lambda x: x>= 80, scores))

scores = [ ("fluke", 80), ("b", 78), ("pass", 95) ]

## filter score >= 80
list(filter(lambda x: x[1]>= 80, scores))

## install new library/ module
!pip install pandas

## working with json
## JavaScript Object Notation

profile = {
    "name" : "fluke",
    "age": 24,
    "movie" : ["The dark knight", "Superman"],
    "city": "Bangkok"
}

## import json
import json

## write json file
with open("profile.json", "w") as file:
  json.dump(profile, file)

## read json file
with open("profile.json", "r") as file:
  data = json.load(file)

print(np.sum(nums),
      np.mean(nums),
      np.std(nums),
      np.median(nums),
      np.var(nums))

## change to numpy array
## array == vector in R
nums = np.array(nums)

## numpy method
print(nums.sum(),
      nums.std(),
      nums.mean(),
      nums.min(),
      nums.max())

## simple web scraping
!pip install gazpacho
## import library (modules)
import requests
from gazpacho import Soup
url = "https://raw.githubusercontent.com/toyeiei/python-test-bc12/refs/heads/main/index.html"
## get request
requests.get(url)
## get request
response = requests.get(url)
response.status_code
web = Soup(response.text) # ทำให้ดูสวยขึ้น
web.find("h1")
web.find("li")

for h2 in web.find("h2"):
  print(h2.strip()) # strip() ลบ html tag ทั้งหมดที่อยู่ในข้อความ เก็บไว้เฉพาะ text

for li in web.find("li"):
  print(li.strip())
